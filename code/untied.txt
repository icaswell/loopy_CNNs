Good job.  You have followed directions.  Asserter passes.
[45mALN> [0m [45mloop outputs: [0m 
[45mALN> [0m [91m[repeating section] adding layer conv_1_unroll=0 with input input[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c37ab150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_2_unroll=0 with input conv_1_unroll=0[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_3_unroll=0 with input conv_2_unroll=0[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747990>, 'num_filters': 3}
[45mALN> [0m [91madding loop:[0m 
[45mALN> [0m [45mloop outputs: ('conv_1', ('conv_3_unroll=0', 'sum'))[0m 
[45mALN> [0m [91m[repeating section] adding layer conv_1_unroll=1 with input ['input', 'conv_3_unroll=0'][0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c37ab150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_2_unroll=1 with input conv_1_unroll=1[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_3_unroll=1 with input conv_2_unroll=1[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747990>, 'num_filters': 3}
[45mALN> [0m [91madding loop:[0m 
[45mALN> [0m [45mloop outputs: ('conv_1', ('conv_3_unroll=1', 'sum'))[0m 
[45mALN> [0m [91m[repeating section] adding layer conv_1_unroll=2 with input ['input', 'conv_3_unroll=1'][0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c37ab150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_2_unroll=2 with input conv_1_unroll=2[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747150>, 'num_filters': 64}
[45mALN> [0m [91m[repeating section] adding layer conv_3_unroll=2 with input conv_2_unroll=2[0m 
{'nonlinearity': <function rectify at 0x7f88c5dc17d0>, 'filter_size': 3, 'pad': 1, 'W': <lasagne.init.GlorotUniform object at 0x7f88c3747990>, 'num_filters': 3}
[45mALN> [0m [94m[after repeating section] adding layer fc_1 with input conv_3_unroll=2[0m 
[45mALN> [0m [45mmarking layer fc_1 as output[0m 
[91mModel has 153655 total parameters[0m 
LoopyCNN instance with the following hyperparameters, layers and loops:[95m
HYPERPARAMETERS:[0m
	n_unrolls=3
	use_batchnorm=True[95m

ARCHITECTURE:[0m
main_stack:
	[93minput [input layer; output_dim=(3, 32, 32)][0m
	[96mconv_1 [conv2d layer; num_filters=64][0m
	[96mconv_2 [conv2d layer; num_filters=64][0m
	[96mconv_3 [conv2d layer; num_filters=3][0m
	[97mfc_1 [dense layer; output_dim=10][0m
loop:
	[96mconv_3 [conv2d layer; num_filters=3][0m
	[96mconv_1 [conv2d layer; num_filters=64][0m
(20000, 3, 32, 32) (20000,)
(1000, 3, 32, 32) (1000,)
*------------------------------------------------------------------------------*
Epoch 7, batch 499:
batchly_train_loss:  1.70883306562
cumulative_train_loss:  1.71225756074
*------------------------------------------------------------------------------*
Epoch 7, batch 999:
batchly_train_loss:  1.68403801759
cumulative_train_loss:  1.69813366527
*------------------------------------------------------------------------------*
Epoch 7, batch 1499:
batchly_train_loss:  1.6553235101
cumulative_train_loss:  1.68385409383
*------------------------------------------------------------------------------*
Epoch 7, batch 1999:
batchly_train_loss:  1.59506524762
cumulative_train_loss:  1.66164577812
*------------------------------------------------------------------------------*
Epoch 7, batch 2499:
batchly_train_loss:  1.66082258666
cumulative_train_loss:  1.66148107395
*------------------------------------------------------------------------------*
Epoch 7, batch 2999:
batchly_train_loss:  1.49644461383
cumulative_train_loss:  1.63396582551
*------------------------------------------------------------------------------*
Epoch 7, batch 3499:
batchly_train_loss:  1.65076389224
cumulative_train_loss:  1.63636623516
*------------------------------------------------------------------------------*
Epoch 7, batch 3999:
batchly_train_loss:  1.608912496
cumulative_train_loss:  1.63293365962
================================================================================
Epoch 7 of 16 took 2414.450s
  training loss:		1.632562
evaluating model...
VALID_LOSS:  1.76403771838
VALID_ACC:  0.349090909091
FULL_TRAIN_LOSS:  1.64296028001
FULL_TRAIN_ACC:  0.419402985075
time to evaluate model: 865.436563969
saving model to ../saved_models/scq_untied_unrolls=3_Mar-11-23:29:18-2016_epoch=7
time to save model: 0.181577920914
*------------------------------------------------------------------------------*
Epoch 8, batch 499:
batchly_train_loss:  1.50751320431
cumulative_train_loss:  1.50696594708
*------------------------------------------------------------------------------*
Epoch 8, batch 999:
batchly_train_loss:  1.53667559513
cumulative_train_loss:  1.5218356408
*------------------------------------------------------------------------------*
Epoch 8, batch 1499:
batchly_train_loss:  1.48109059879
cumulative_train_loss:  1.50824489963
*------------------------------------------------------------------------------*
Epoch 8, batch 1999:
batchly_train_loss:  1.47844948546
cumulative_train_loss:  1.5007923198
*------------------------------------------------------------------------------*
Epoch 8, batch 2499:
batchly_train_loss:  1.4436006676
cumulative_train_loss:  1.4893494122
*------------------------------------------------------------------------------*
Epoch 8, batch 2999:
batchly_train_loss:  1.43313771525
cumulative_train_loss:  1.47997767213
*------------------------------------------------------------------------------*
Epoch 8, batch 3499:
batchly_train_loss:  1.52054644574
cumulative_train_loss:  1.48577486755
*------------------------------------------------------------------------------*
Epoch 8, batch 3999:
batchly_train_loss:  1.48475159293
cumulative_train_loss:  1.48564692624
================================================================================
Epoch 8 of 16 took 2434.046s
  training loss:		1.485281
evaluating model...
VALID_LOSS:  1.41491455484
VALID_ACC:  0.611818181818
FULL_TRAIN_LOSS:  1.20142152032
FULL_TRAIN_ACC:  0.595771144279
time to evaluate model: 856.270940065
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-00:24:09-2016_epoch=8
time to save model: 0.180170059204
*------------------------------------------------------------------------------*
Epoch 9, batch 499:
batchly_train_loss:  1.20498550454
cumulative_train_loss:  1.20438308882
*------------------------------------------------------------------------------*
Epoch 9, batch 999:
batchly_train_loss:  1.45013589077
cumulative_train_loss:  1.3273824892
*------------------------------------------------------------------------------*
Epoch 9, batch 1499:
batchly_train_loss:  1.45009430068
cumulative_train_loss:  1.36831371384
*------------------------------------------------------------------------------*
Epoch 9, batch 1999:
batchly_train_loss:  1.33131484162
cumulative_train_loss:  1.35905936861
*------------------------------------------------------------------------------*
Epoch 9, batch 2499:
batchly_train_loss:  1.32289584166
cumulative_train_loss:  1.35182376898
*------------------------------------------------------------------------------*
Epoch 9, batch 2999:
batchly_train_loss:  1.33597652345
cumulative_train_loss:  1.3491816807
*------------------------------------------------------------------------------*
Epoch 9, batch 3499:
batchly_train_loss:  1.24076849567
cumulative_train_loss:  1.33368965654
*------------------------------------------------------------------------------*
Epoch 9, batch 3999:
batchly_train_loss:  1.43522091359
cumulative_train_loss:  1.34638423732
================================================================================
Epoch 9 of 16 took 2402.873s
  training loss:		1.346088
evaluating model...
VALID_LOSS:  1.46976659456
VALID_ACC:  0.482727272727
FULL_TRAIN_LOSS:  1.25622168967
FULL_TRAIN_ACC:  0.562338308458
time to evaluate model: 861.100630999
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-01:18:33-2016_epoch=9
time to save model: 0.177240848541
*------------------------------------------------------------------------------*
Epoch 10, batch 499:
batchly_train_loss:  1.28453132997
cumulative_train_loss:  1.28408357189
*------------------------------------------------------------------------------*
Epoch 10, batch 999:
batchly_train_loss:  1.17866115955
cumulative_train_loss:  1.23131960175
*------------------------------------------------------------------------------*
Epoch 10, batch 1499:
batchly_train_loss:  1.20202791752
cumulative_train_loss:  1.2215491934
*------------------------------------------------------------------------------*
Epoch 10, batch 1999:
batchly_train_loss:  1.25452199572
cumulative_train_loss:  1.22979651764
*------------------------------------------------------------------------------*
Epoch 10, batch 2499:
batchly_train_loss:  1.21553149821
cumulative_train_loss:  1.2269423721
*------------------------------------------------------------------------------*
Epoch 10, batch 2999:
batchly_train_loss:  1.34178532961
cumulative_train_loss:  1.24608924731
*------------------------------------------------------------------------------*
Epoch 10, batch 3499:
batchly_train_loss:  1.34421512795
cumulative_train_loss:  1.26011123654
*------------------------------------------------------------------------------*
Epoch 10, batch 3999:
batchly_train_loss:  1.29646825914
cumulative_train_loss:  1.2646570008
================================================================================
Epoch 10 of 16 took 2395.957s
  training loss:		1.264362
evaluating model...
VALID_LOSS:  1.45423568072
VALID_ACC:  0.551818181818
FULL_TRAIN_LOSS:  1.20396432574
FULL_TRAIN_ACC:  0.587412935323
time to evaluate model: 859.574124098
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-02:12:49-2016_epoch=10
time to save model: 0.177078962326
*------------------------------------------------------------------------------*
Epoch 11, batch 499:
batchly_train_loss:  1.13743083266
cumulative_train_loss:  1.13700450067
*------------------------------------------------------------------------------*
Epoch 11, batch 999:
batchly_train_loss:  1.20795671418
cumulative_train_loss:  1.17251611904
*------------------------------------------------------------------------------*
Epoch 11, batch 1499:
batchly_train_loss:  1.18237407929
cumulative_train_loss:  1.17580429791
*------------------------------------------------------------------------------*
Epoch 11, batch 1999:
batchly_train_loss:  1.18560768149
cumulative_train_loss:  1.17825636984
*------------------------------------------------------------------------------*
Epoch 11, batch 2499:
batchly_train_loss:  1.30115234814
cumulative_train_loss:  1.20284540111
*------------------------------------------------------------------------------*
Epoch 11, batch 2999:
batchly_train_loss:  1.17600092073
cumulative_train_loss:  1.19836982919
*------------------------------------------------------------------------------*
Epoch 11, batch 3499:
batchly_train_loss:  1.27718216911
cumulative_train_loss:  1.20963195264
*------------------------------------------------------------------------------*
Epoch 11, batch 3999:
batchly_train_loss:  1.25137594598
cumulative_train_loss:  1.21485125664
================================================================================
Epoch 11 of 16 took 2405.046s
  training loss:		1.214591
evaluating model...
VALID_LOSS:  1.47917500143
VALID_ACC:  0.548181818182
FULL_TRAIN_LOSS:  1.08136038599
FULL_TRAIN_ACC:  0.620447761194
time to evaluate model: 863.964031935
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-03:07:18-2016_epoch=11
time to save model: 0.181913852692
*------------------------------------------------------------------------------*
Epoch 12, batch 499:
batchly_train_loss:  1.2476318867
cumulative_train_loss:  1.24735138976
*------------------------------------------------------------------------------*
Epoch 12, batch 999:
batchly_train_loss:  1.11275363327
cumulative_train_loss:  1.17998514527
*------------------------------------------------------------------------------*
Epoch 12, batch 1499:
batchly_train_loss:  1.12044765923
cumulative_train_loss:  1.16012607721
*------------------------------------------------------------------------------*
Epoch 12, batch 1999:
batchly_train_loss:  1.17137693388
cumulative_train_loss:  1.16294019844
*------------------------------------------------------------------------------*
Epoch 12, batch 2499:
batchly_train_loss:  1.07056118956
cumulative_train_loss:  1.14445700339
*------------------------------------------------------------------------------*
Epoch 12, batch 2999:
batchly_train_loss:  1.13881556379
cumulative_train_loss:  1.14351644994
*------------------------------------------------------------------------------*
Epoch 12, batch 3499:
batchly_train_loss:  1.17795421515
cumulative_train_loss:  1.14843753671
*------------------------------------------------------------------------------*
Epoch 12, batch 3999:
batchly_train_loss:  1.21601764742
cumulative_train_loss:  1.15688716295
================================================================================
Epoch 12 of 16 took 2410.735s
  training loss:		1.156337
evaluating model...
VALID_LOSS:  1.23629253043
VALID_ACC:  0.575454545455
FULL_TRAIN_LOSS:  1.03096689027
FULL_TRAIN_ACC:  0.640895522388
time to evaluate model: 864.532407999
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-04:01:53-2016_epoch=12
time to save model: 0.392461061478
*------------------------------------------------------------------------------*
Epoch 13, batch 499:
batchly_train_loss:  1.05911945016
cumulative_train_loss:  1.06101682976
*------------------------------------------------------------------------------*
Epoch 13, batch 999:
batchly_train_loss:  1.12172462742
cumulative_train_loss:  1.09140111288
*------------------------------------------------------------------------------*
Epoch 13, batch 1499:
batchly_train_loss:  1.04843194053
cumulative_train_loss:  1.07706850035
*------------------------------------------------------------------------------*
Epoch 13, batch 1999:
batchly_train_loss:  1.11970910483
cumulative_train_loss:  1.08773398421
*------------------------------------------------------------------------------*
Epoch 13, batch 2499:
batchly_train_loss:  1.11875659432
cumulative_train_loss:  1.09394098904
*------------------------------------------------------------------------------*
Epoch 13, batch 2999:
batchly_train_loss:  1.19119883892
cumulative_train_loss:  1.1101560357
*------------------------------------------------------------------------------*
Epoch 13, batch 3499:
batchly_train_loss:  1.15353756366
cumulative_train_loss:  1.11635516802
*------------------------------------------------------------------------------*
Epoch 13, batch 3999:
batchly_train_loss:  1.11316106991
cumulative_train_loss:  1.11595580591
================================================================================
Epoch 13 of 16 took 2409.180s
  training loss:		1.115734
evaluating model...
VALID_LOSS:  1.35100450864
VALID_ACC:  0.56
FULL_TRAIN_LOSS:  1.02555315409
FULL_TRAIN_ACC:  0.629154228856
time to evaluate model: 867.209163904
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-04:56:30-2016_epoch=13
time to save model: 0.180198907852
*------------------------------------------------------------------------------*
Epoch 14, batch 499:
batchly_train_loss:  1.07241252369
cumulative_train_loss:  1.07186443018
*------------------------------------------------------------------------------*
Epoch 14, batch 999:
batchly_train_loss:  1.06629413251
cumulative_train_loss:  1.06907649341
*------------------------------------------------------------------------------*
Epoch 14, batch 1499:
batchly_train_loss:  1.12611232436
cumulative_train_loss:  1.08810112014
*------------------------------------------------------------------------------*
Epoch 14, batch 1999:
batchly_train_loss:  1.13693996979
cumulative_train_loss:  1.10031694047
*------------------------------------------------------------------------------*
Epoch 14, batch 2499:
batchly_train_loss:  1.07956916442
cumulative_train_loss:  1.09616572477
*------------------------------------------------------------------------------*
Epoch 14, batch 2999:
batchly_train_loss:  1.09328034441
cumulative_train_loss:  1.09568466769
*------------------------------------------------------------------------------*
Epoch 14, batch 3499:
batchly_train_loss:  1.08184043026
cumulative_train_loss:  1.09370635425
*------------------------------------------------------------------------------*
Epoch 14, batch 3999:
batchly_train_loss:  1.026866061
cumulative_train_loss:  1.08534922832
================================================================================
Epoch 14 of 16 took 2395.488s
  training loss:		1.085075
evaluating model...
VALID_LOSS:  1.46374256155
VALID_ACC:  0.534545454545
FULL_TRAIN_LOSS:  1.08110644457
FULL_TRAIN_ACC:  0.632338308458
time to evaluate model: 865.660156965
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-05:50:51-2016_epoch=14
time to save model: 0.18045091629
*------------------------------------------------------------------------------*
Epoch 15, batch 499:
batchly_train_loss:  1.07446672973
cumulative_train_loss:  1.07446567322
*------------------------------------------------------------------------------*
Epoch 15, batch 999:
batchly_train_loss:  1.02142356552
cumulative_train_loss:  1.04791807177
*------------------------------------------------------------------------------*
Epoch 15, batch 1499:
batchly_train_loss:  1.01742999179
cumulative_train_loss:  1.03774859879
*------------------------------------------------------------------------------*
Epoch 15, batch 1999:
batchly_train_loss:  0.970493867775
cumulative_train_loss:  1.02092650499
*------------------------------------------------------------------------------*
Epoch 15, batch 2499:
batchly_train_loss:  1.08140042035
cumulative_train_loss:  1.03302612791
*------------------------------------------------------------------------------*
Epoch 15, batch 2999:
batchly_train_loss:  1.05075368951
cumulative_train_loss:  1.03598170671
*------------------------------------------------------------------------------*
Epoch 15, batch 3499:
batchly_train_loss:  1.13899600854
cumulative_train_loss:  1.05070224141
*------------------------------------------------------------------------------*
Epoch 15, batch 3999:
batchly_train_loss:  1.18699452321
cumulative_train_loss:  1.06774303683
================================================================================
Epoch 15 of 16 took 2405.580s
  training loss:		1.067667
evaluating model...
VALID_LOSS:  1.58131243154
VALID_ACC:  0.488181818182
FULL_TRAIN_LOSS:  0.93340963341
FULL_TRAIN_ACC:  0.665373134328
time to evaluate model: 861.415078163
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-06:45:18-2016_epoch=15
time to save model: 0.183917045593
*------------------------------------------------------------------------------*
Epoch 16, batch 499:
batchly_train_loss:  1.03086998089
cumulative_train_loss:  1.02926909273
*------------------------------------------------------------------------------*
Epoch 16, batch 999:
batchly_train_loss:  0.912876208224
cumulative_train_loss:  0.971014395778
*------------------------------------------------------------------------------*
Epoch 16, batch 1499:
batchly_train_loss:  0.999109281339
cumulative_train_loss:  0.980385605105
*------------------------------------------------------------------------------*
Epoch 16, batch 1999:
batchly_train_loss:  0.982019006818
cumulative_train_loss:  0.98079415981
*------------------------------------------------------------------------------*
Epoch 16, batch 2499:
batchly_train_loss:  1.03010454534
cumulative_train_loss:  0.990660183326
*------------------------------------------------------------------------------*
Epoch 16, batch 2999:
batchly_train_loss:  1.06810059467
cumulative_train_loss:  1.00357122223
*------------------------------------------------------------------------------*
Epoch 16, batch 3499:
batchly_train_loss:  1.12674514453
cumulative_train_loss:  1.02117252579
*------------------------------------------------------------------------------*
Epoch 16, batch 3999:
batchly_train_loss:  1.07127941137
cumulative_train_loss:  1.02743745272
================================================================================
Epoch 16 of 16 took 2405.010s
  training loss:		1.027067
evaluating model...
VALID_LOSS:  1.6097000731
VALID_ACC:  0.442727272727
FULL_TRAIN_LOSS:  0.969459403666
FULL_TRAIN_ACC:  0.676119402985
time to evaluate model: 863.800584078
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-07:39:47-2016_epoch=16
time to save model: 0.178529024124
*------------------------------------------------------------------------------*
Epoch 17, batch 499:
batchly_train_loss:  1.02173455795
cumulative_train_loss:  1.02263329367
*------------------------------------------------------------------------------*
Epoch 17, batch 999:
batchly_train_loss:  1.03737119218
cumulative_train_loss:  1.03000961925
*------------------------------------------------------------------------------*
Epoch 17, batch 1499:
batchly_train_loss:  0.994936410571
cumulative_train_loss:  1.01831075044
*------------------------------------------------------------------------------*
Epoch 17, batch 1999:
batchly_train_loss:  0.943649786231
cumulative_train_loss:  0.999636172102
*------------------------------------------------------------------------------*
Epoch 17, batch 2499:
batchly_train_loss:  0.956033031383
cumulative_train_loss:  0.990912054311
*------------------------------------------------------------------------------*
Epoch 17, batch 2999:
batchly_train_loss:  1.04791963086
cumulative_train_loss:  1.00041648521
*------------------------------------------------------------------------------*
Epoch 17, batch 3499:
batchly_train_loss:  0.965859927157
cumulative_train_loss:  0.995478423187
*------------------------------------------------------------------------------*
Epoch 17, batch 3999:
batchly_train_loss:  0.982641144991
cumulative_train_loss:  0.993873362147
================================================================================
Epoch 17 of 16 took 2405.409s
  training loss:		0.993491
evaluating model...
VALID_LOSS:  1.56081604845
VALID_ACC:  0.522727272727
FULL_TRAIN_LOSS:  0.900417249342
FULL_TRAIN_ACC:  0.696417910448
time to evaluate model: 865.590682983
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-08:34:19-2016_epoch=17
time to save model: 0.17885518074
*------------------------------------------------------------------------------*
Epoch 18, batch 499:
batchly_train_loss:  0.981688009335
cumulative_train_loss:  0.982737082899
*------------------------------------------------------------------------------*
Epoch 18, batch 999:
batchly_train_loss:  0.988627764944
cumulative_train_loss:  0.985685372211
*------------------------------------------------------------------------------*
Epoch 18, batch 1499:
batchly_train_loss:  0.940855559505
cumulative_train_loss:  0.970732132483
*------------------------------------------------------------------------------*
Epoch 18, batch 1999:
batchly_train_loss:  1.02071481085
cumulative_train_loss:  0.983234053034
*------------------------------------------------------------------------------*
Epoch 18, batch 2499:
batchly_train_loss:  0.987537528829
cumulative_train_loss:  0.984095092609
*------------------------------------------------------------------------------*
Epoch 18, batch 2999:
batchly_train_loss:  0.970413511443
cumulative_train_loss:  0.98181406874
*------------------------------------------------------------------------------*
Epoch 18, batch 3499:
batchly_train_loss:  0.992356401605
cumulative_train_loss:  0.983320546714
*------------------------------------------------------------------------------*
Epoch 18, batch 3999:
batchly_train_loss:  0.986170171516
cumulative_train_loss:  0.983676838887
================================================================================
Epoch 18 of 16 took 2402.420s
  training loss:		0.983281
evaluating model...
VALID_LOSS:  1.53652974683
VALID_ACC:  0.52
FULL_TRAIN_LOSS:  0.903783339455
FULL_TRAIN_ACC:  0.686119402985
time to evaluate model: 868.364871025
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-09:28:50-2016_epoch=18
time to save model: 0.181925058365
*------------------------------------------------------------------------------*
Epoch 19, batch 499:
batchly_train_loss:  0.854405428427
cumulative_train_loss:  0.855350938633
*------------------------------------------------------------------------------*
Epoch 19, batch 999:
batchly_train_loss:  0.900133232612
cumulative_train_loss:  0.877764499183
*------------------------------------------------------------------------------*
Epoch 19, batch 1499:
batchly_train_loss:  1.01292782104
cumulative_train_loss:  0.922848996132
*------------------------------------------------------------------------------*
Epoch 19, batch 1999:
batchly_train_loss:  0.864119361255
cumulative_train_loss:  0.908159242536
*------------------------------------------------------------------------------*
Epoch 19, batch 2499:
batchly_train_loss:  0.930241200915
cumulative_train_loss:  0.912577401475
*------------------------------------------------------------------------------*
Epoch 19, batch 2999:
batchly_train_loss:  0.981657667835
cumulative_train_loss:  0.924094618274
*------------------------------------------------------------------------------*
Epoch 19, batch 3499:
batchly_train_loss:  0.974601288339
cumulative_train_loss:  0.931311918941
*------------------------------------------------------------------------------*
Epoch 19, batch 3999:
batchly_train_loss:  1.03792974934
cumulative_train_loss:  0.944642480381
================================================================================
Epoch 19 of 16 took 2411.157s
  training loss:		0.944362
evaluating model...
VALID_LOSS:  1.48156006915
VALID_ACC:  0.510909090909
FULL_TRAIN_LOSS:  0.957593416834
FULL_TRAIN_ACC:  0.697860696517
time to evaluate model: 872.291288137
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-10:23:33-2016_epoch=19
time to save model: 0.183118104935
*------------------------------------------------------------------------------*
Epoch 20, batch 499:
batchly_train_loss:  0.821776937271
cumulative_train_loss:  0.821885552574
*------------------------------------------------------------------------------*
Epoch 20, batch 999:
batchly_train_loss:  0.876447035149
cumulative_train_loss:  0.84919360191
*------------------------------------------------------------------------------*
Epoch 20, batch 1499:
batchly_train_loss:  1.02518321878
cumulative_train_loss:  0.907895942429
*------------------------------------------------------------------------------*
Epoch 20, batch 1999:
batchly_train_loss:  0.93439302255
cumulative_train_loss:  0.914523526251
*------------------------------------------------------------------------------*
Epoch 20, batch 2499:
batchly_train_loss:  1.03393380402
cumulative_train_loss:  0.938415138449
*------------------------------------------------------------------------------*
Epoch 20, batch 2999:
batchly_train_loss:  0.875410877405
cumulative_train_loss:  0.927910926871
*------------------------------------------------------------------------------*
Epoch 20, batch 3499:
batchly_train_loss:  0.993924290447
cumulative_train_loss:  0.937344102575
*------------------------------------------------------------------------------*
Epoch 20, batch 3999:
batchly_train_loss:  0.92225113457
cumulative_train_loss:  0.935457009801
================================================================================
Epoch 20 of 16 took 2426.639s
  training loss:		0.935546
evaluating model...
VALID_LOSS:  1.4737487356
VALID_ACC:  0.536363636364
FULL_TRAIN_LOSS:  0.881896963914
FULL_TRAIN_ACC:  0.67263681592
time to evaluate model: 873.174459934
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-11:18:33-2016_epoch=20
time to save model: 0.180721998215
*------------------------------------------------------------------------------*
Epoch 21, batch 499:
batchly_train_loss:  0.911175528244
cumulative_train_loss:  0.908534974277
*------------------------------------------------------------------------------*
Epoch 21, batch 999:
batchly_train_loss:  0.885794483549
cumulative_train_loss:  0.897153347286
*------------------------------------------------------------------------------*
Epoch 21, batch 1499:
batchly_train_loss:  0.920793205128
cumulative_train_loss:  0.905038556707
*------------------------------------------------------------------------------*
Epoch 21, batch 1999:
batchly_train_loss:  0.892981476821
cumulative_train_loss:  0.902022778846
*------------------------------------------------------------------------------*
Epoch 21, batch 2499:
batchly_train_loss:  0.92088335371
cumulative_train_loss:  0.905796403269
*------------------------------------------------------------------------------*
Epoch 21, batch 2999:
batchly_train_loss:  0.973852393218
cumulative_train_loss:  0.917142850409
*------------------------------------------------------------------------------*
Epoch 21, batch 3499:
batchly_train_loss:  0.914209949094
cumulative_train_loss:  0.916723744763
*------------------------------------------------------------------------------*
Epoch 21, batch 3999:
batchly_train_loss:  0.976082771722
cumulative_train_loss:  0.924145478566
================================================================================
Epoch 21 of 16 took 2425.054s
  training loss:		0.924041
evaluating model...
VALID_LOSS:  1.47243507379
VALID_ACC:  0.598181818182
FULL_TRAIN_LOSS:  0.798345250367
FULL_TRAIN_ACC:  0.72855721393
time to evaluate model: 869.56888485
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-12:13:28-2016_epoch=21
time to save model: 0.182993888855
*------------------------------------------------------------------------------*
Epoch 22, batch 499:
batchly_train_loss:  0.83361164271
cumulative_train_loss:  0.832415396879
*------------------------------------------------------------------------------*
Epoch 22, batch 999:
batchly_train_loss:  0.847663219337
cumulative_train_loss:  0.840046939651
*------------------------------------------------------------------------------*
Epoch 22, batch 1499:
batchly_train_loss:  0.946663851669
cumulative_train_loss:  0.875609618776
*------------------------------------------------------------------------------*
Epoch 22, batch 1999:
batchly_train_loss:  0.841513221204
cumulative_train_loss:  0.867081255201
*------------------------------------------------------------------------------*
Epoch 22, batch 2499:
batchly_train_loss:  0.880522220306
cumulative_train_loss:  0.86977052393
*------------------------------------------------------------------------------*
Epoch 22, batch 2999:
batchly_train_loss:  0.947417058153
cumulative_train_loss:  0.882715928102
*------------------------------------------------------------------------------*
Epoch 22, batch 3499:
batchly_train_loss:  0.948463133334
cumulative_train_loss:  0.892111070318
*------------------------------------------------------------------------------*
Epoch 22, batch 3999:
batchly_train_loss:  0.931902277425
cumulative_train_loss:  0.897086214993
================================================================================
Epoch 22 of 16 took 2417.278s
  training loss:		0.896754
evaluating model...
VALID_LOSS:  1.53983445322
VALID_ACC:  0.560909090909
FULL_TRAIN_LOSS:  0.852152448676
FULL_TRAIN_ACC:  0.69776119403
time to evaluate model: 867.714461803
saving model to ../saved_models/scq_untied_unrolls=3_Mar-12-13:08:13-2016_epoch=22
time to save model: 0.397796869278
{'valid_loss': [1.764037718377333, 1.4149145548394615, 1.46976659456477, 1.4542356807164265, 1.4791750014270038, 1.2362925304341223, 1.3510045086387388, 1.4637425615543007, 1.581312431537313, 1.6097000730970896, 1.5608160484483891, 1.5365297468279351, 1.4815600691475768, 1.4737487355981869, 1.4724350737883056, 1.5398344532206807], 'full_train_acc': [0.41940298507462642, 0.59577114427860722, 0.56233830845771127, 0.58741293532338335, 0.62044776119403022, 0.64089552238806013, 0.62915422885572181, 0.63233830845771266, 0.66537313432835843, 0.67611940298507511, 0.69641791044776102, 0.68611940298507423, 0.69786069651741245, 0.67263681592039715, 0.72855721393034767, 0.6977611940298506], 'valid_acc': [0.34909090909090912, 0.61181818181818182, 0.48272727272727267, 0.55181818181818187, 0.54818181818181821, 0.57545454545454544, 0.56000000000000005, 0.53454545454545466, 0.48818181818181822, 0.44272727272727275, 0.52272727272727271, 0.51999999999999991, 0.51090909090909087, 0.53636363636363626, 0.59818181818181815, 0.56090909090909102], 'batchly_train_loss': [1.7088330656161848, 1.6840380175872391, 1.6553235100987216, 1.5950652476177158, 1.6608225866649238, 1.4964446138279464, 1.6507638922366994, 1.608912496003658, 1.507513204306357, 1.536675595125951, 1.481090598791692, 1.4784494854566461, 1.4436006676022624, 1.4331377152469786, 1.5205464457374975, 1.4847515929288089, 1.2049855045371252, 1.4501358907723285, 1.4500943006822407, 1.3313148416233551, 1.3228958416632179, 1.3359765234470777, 1.2407684956653207, 1.4352209135877978, 1.2845313299736041, 1.1786611595458081, 1.2020279175233612, 1.2545219957165372, 1.2155314982082459, 1.3417853296104443, 1.3442151279493011, 1.2964682591413861, 1.1374308326592788, 1.2079567141802567, 1.1823740792928294, 1.1856076814875893, 1.3011523481390757, 1.1760009207263828, 1.2771821691118754, 1.2513759459787073, 1.2476318867031262, 1.1127536332740462, 1.1204476592331032, 1.1713769338782276, 1.0705611895637697, 1.1388155637894133, 1.177954215148602, 1.216017647423691, 1.0591194501579966, 1.1217246274221988, 1.0484319405332494, 1.119709104827098, 1.118756594318397, 1.1911988389190291, 1.1535375636646101, 1.1131610699088552, 1.0724125236857867, 1.0662941325118089, 1.1261123243618476, 1.1369399697900322, 1.079569164421861, 1.0932803444141161, 1.0818404302606275, 1.0268660610000369, 1.074466729734106, 1.021423565521945, 1.0174299917867466, 0.97049386777482771, 1.0814004203525347, 1.0507536895114751, 1.1389960085391495, 1.186994523208228, 1.0308699808893167, 0.91287620822399385, 0.99910928133945243, 0.98201900681755738, 1.0301045453426583, 1.0681005946652551, 1.1267451445307461, 1.071279411372692, 1.0217345579485511, 1.0373711921818574, 0.99493641057115156, 0.94364978623139328, 0.95603303138343931, 1.0479196308578911, 0.96585992715736835, 0.98264114499070032, 0.98168800933503497, 0.988627764944077, 0.94085555950536282, 1.0207148108458273, 0.98753752882905299, 0.97041351144310484, 0.99235640160488392, 0.98617017151604403, 0.85440542842738987, 0.90013323261248213, 1.0129278210350054, 0.86411936125527489, 0.93024120091476425, 0.98165766783523867, 0.97460128833866544, 1.0379297493368667, 0.82177693727074896, 0.87644703514861377, 1.0251832187845844, 0.93439302254993317, 1.033933804017872, 0.87541087740485934, 0.99392429044652386, 0.92225113457008778, 0.91117552824433456, 0.88579448354937129, 0.92079320512799867, 0.89298147682053597, 0.92088335370954744, 0.9738523932180756, 0.91420994909367226, 0.97608277172175739, 0.83361164270992061, 0.84766321933745814, 0.94666385166937828, 0.8415132212037163, 0.88052222030649874, 0.94741705815283273, 0.94846313333400356, 0.93190227742496534, 0.46550507795905133], 'cumulative_train_loss': [1.71225756073766, 1.6981336652669801, 1.6838540938299373, 1.6616457781190286, 1.6614810739465378, 1.6339658255106271, 1.6363662351599637, 1.6329336596215407, 1.5069659470782015, 1.521835640795792, 1.5082448996336522, 1.5007923197994819, 1.4893494121969972, 1.4799776721253044, 1.4857748675543132, 1.485646926240797, 1.2043830888215039, 1.3273824891972934, 1.368313713842038, 1.3590593686147525, 1.3518237689845951, 1.349181680698913, 1.3336896565443557, 1.3463842373199784, 1.284083571886145, 1.2313196017458345, 1.2215491933994438, 1.2297965176408407, 1.2269423720961052, 1.246089247306899, 1.2601112365384515, 1.2646570008048839, 1.1370045006706009, 1.1725161190438018, 1.175804297912725, 1.1782563698424062, 1.2028454011142506, 1.1983698291922986, 1.2096319526446524, 1.2148512566374052, 1.2473513897617494, 1.179985145273412, 1.1601260772146038, 1.1629401984411232, 1.1444570033876311, 1.1435164499367778, 1.1484375367061148, 1.1568871629523716, 1.0610168297618277, 1.0914011128751249, 1.0770685003528175, 1.0877339842133182, 1.0939409890362617, 1.1101560356989437, 1.1163551680175583, 1.1159558059134447, 1.0718644301761613, 1.0690764934072154, 1.0881011201432511, 1.1003169404651063, 1.0961657247701788, 1.0956846676918095, 1.0937063542549446, 1.0853492283165977, 1.0744656732246312, 1.0479180717718348, 1.0377485987948207, 1.020926504992921, 1.0330261279140114, 1.0359817067065209, 1.050702241406811, 1.0677430368308445, 1.0292690927254333, 0.97101439577776583, 0.98038560510454476, 0.98079415981015261, 0.99066018332606209, 1.0035712222288939, 1.021172525787319, 1.0274374527172228, 1.0226332936657576, 1.0300096192493906, 1.0183107504441067, 0.99963617210175593, 0.9909120543109774, 1.00041648521243, 0.99547842318684288, 0.99387336214706534, 0.98273708289939254, 0.98568537221104591, 0.97073213248266665, 0.98323405303373324, 0.98409509260862682, 0.9818140687397493, 0.98332054671418967, 0.98367683888746416, 0.85535093863319234, 0.87776449918338806, 0.92284899613189053, 0.90815924253593927, 0.9125774014752781, 0.92409461827420525, 0.93131191894074672, 0.94464248038062193, 0.82188555257351226, 0.84919360191039883, 0.90789594242880611, 0.91452352625099931, 0.93841513844925306, 0.92791092687132748, 0.93734410257512746, 0.9354570098013042, 0.90853497427745056, 0.89715334728642093, 0.90503855670656097, 0.90202277884612458, 0.90579640326857713, 0.91714285040920551, 0.9167237447625155, 0.92414547856587248, 0.83241539687858379, 0.84004693965079424, 0.87560961877640509, 0.86708125520144552, 0.86977052392994658, 0.88271592810181709, 0.8921110703184767, 0.89708621499295604], 'full_train_loss': [1.6429602800116112, 1.2014215203208509, 1.2562216896742255, 1.2039643257352342, 1.0813603859922138, 1.0309668902721891, 1.025553154092717, 1.0811064445699969, 0.93340963341029792, 0.969459403666034, 0.90041724934153733, 0.90378333945460332, 0.95759341683375609, 0.88189696391350469, 0.79834525036744042, 0.8521524486760883]}
